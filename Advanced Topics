## Recurrent Neural Network(RNN)

- RNN 중 LSTM에 대해 다뤄볼 것. RNN 중 거의 표준으로 사용되는 중 

- 이전까지의 정보를 담고 있는 메모리 + 현재의 입력 같이 고려 

```
RNN 쓰는 이유 : 시간적으로 서로 연관성있는 데이터를 처리하기 위함 
Longer - Term Dependencies : 실제로는 이전 문장만 고려해서 예측하는 것이 아닌 
한참 전에 있는 문장까지 머리속에 들어가있어야 현재를 올바르게 유추할 수 있음 
LSTM : Longer-Term Dependencies를 잡는데 특화된 방법 - 한참 전 정보도 같이 고려해 유추 
```

## Forget Gate

## Input Gate

## Update

## Output Gate


```
Forget, Input Gate 모두 이전 값을 얼마나 버릴지와. 
현재입력과 이전 출력으로 얻어지는 값을 cell state에 얼마나 올릴지 정해줌 
결국 이 모든 것의 주체가 cell State가 됨
```
## 복잡해서 노트필기함
